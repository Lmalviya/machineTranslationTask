{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWdNbYzypLfn/RJppIWkDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lmalviya/machineTranslationTask/blob/main/TransformerFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scop of the notebook:\n",
        "  1. built vanila transformer from scretch\n",
        "  2. train it for languge tranlation english to italian\n"
      ],
      "metadata": {
        "id": "0MRmtg7fyhXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Transformer from scretch"
      ],
      "metadata": {
        "id": "TRmZuHn6eZQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w2duzDHNxynY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word embedding"
      ],
      "metadata": {
        "id": "i000sBhRzFH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordEmbedding(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super().__init__()\n",
        "    # d_model: it is the embedding vector size\n",
        "    # vocab_size: number of words present into vocab\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x)*math.sqrt(self.d_model)  ## mention in the paper \"sqrt(self.d_model)\"\n"
      ],
      "metadata": {
        "id": "ZLLTo0xyyw0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Postional Embedding"
      ],
      "metadata": {
        "id": "aVmtMO1I1ZeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PostionalEmbedding(nn.Module):\n",
        "  def __init__(self, d_model: int, seq_len: int, dropout_p: float):\n",
        "    super().__init__()\n",
        "    # seq_len: number of tokens present in the input\n",
        "    # dropout: used for regularization\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.seq_len = seq_len\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    # create a matrix of shape (seq_len, d_model)\n",
        "    self.pe = torch.zeros(self.seq_len, self.d_model) # postional embedding for each token\n",
        "\n",
        "    # create vector of shape (seq_len, 1)\n",
        "    position = torch.arrang(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arrang(0, d_model, 2).float()*(-math.log(10000.0)/d_model) )\n",
        "\n",
        "    # apply sin at even postion\n",
        "    self.pe[:, 0::2] = math.sin(position * div_term)\n",
        "    self.pe[:, 1::2] = math.cos(position * div_term)\n",
        "\n",
        "    # now we have to add the batch dim\n",
        "    self.pe = self.pe.unsqueeze(0) # (1, seq_len, d_model)\n",
        "\n",
        "    # now define the tensor into buffer\n",
        "    # when you have tensor which is not learnable parameter\n",
        "    # but you want to save when model is save, then you have to put it in register buffer\n",
        "    self.register_buffer('pe', self.pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + (self.pe[:, :x.shape(0), :]).requires_grad(False)\n",
        "    return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "6HIdZWLOywyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer normalization"
      ],
      "metadata": {
        "id": "hPAQuyvFRDCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, eps:float = 10**-6):\n",
        "    super().__init__()\n",
        "    # We also introduce two parameters, usually called gamma (multiplicative) and beta (additive)\n",
        "    # that introduce some fluctuations in the data, because maybe having all values between 0 and 1\n",
        "    # may be too restrictive for the network. The network will learn to tune these two parameters to\n",
        "    # introduce fluctuations when necessary.\n",
        "\n",
        "    self.eps = eps\n",
        "    self.gamma = nn.Parameter(torch.once(1))  # multiplicative\n",
        "    self.beta = nn.Parameter(torch.zeros(1)) # Additative\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True) #usually mean() remove the dim, to keep the dim we used the keepdim=True\n",
        "    std = x.std(dim=-1, keepdim=True)\n",
        "    return self.gamm*(x - mean)/(std + self.eps) + self.beta\n",
        "\n"
      ],
      "metadata": {
        "id": "waKplWzjRC0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed forward block"
      ],
      "metadata": {
        "id": "R4mOntLQTLi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ff: int, dropout_p: float =0.1):\n",
        "    self.linear_1 = nn.Linear(d_model, d_ff) #W1 and B1\n",
        "    self.linear_2 = nn.Linear(d_ff, d_model) #W2 and B2\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input: (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model) output\n",
        "    return self.linear_2(self.dropout(self.relu(self.linear_1(x))))\n"
      ],
      "metadata": {
        "id": "XwKvn4Ifywv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-head Attention"
      ],
      "metadata": {
        "id": "ItBiW5j3U5VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttentionBlock(nn.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(self, d_model: int, head: int, dropout_p: float):\n",
        "    # we take input and replecate into three vector each vector name as follows: key, query, value\n",
        "    # we three matrix caled: key_mul, query_mul, val_mul\n",
        "    # multiply each vectoer with its corresponding matrix and get output which we called key_hat_mat, query_hat_mat, value_hat_mat\n",
        "    # each vecter key_hat_mat, query_hat_mat, value_hat_mat divide alog the d_model dim\n",
        "    # means each head full access of the sequence but different part of each word\n",
        "\n",
        "    self.head = head\n",
        "    self.d_model = d_model\n",
        "    self.attention_score = None\n",
        "    assert d_model % head != 0,  'd_model is not divisible by head'\n",
        "\n",
        "    self.d_k = self.d_model // self.head\n",
        "    self.w_q = nn.Linear(d_model, d_model)\n",
        "    self.w_k = nn.Linear(d_model, d_model)\n",
        "    self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.w_o = nn.Linear(d_model, d_model)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "    d_k = query.shape[-1]\n",
        "\n",
        "    attention_score = (query @ key.transpose(-2, -1))/math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "      attention_score.maksed_fill(mask == 0, -1e9) # In the mask where mask[i][j] == 0, replace -1e9 in the attention_score\n",
        "\n",
        "    attention_score = attention_score.softmax(dim = -1) # (batch, h, seq_len, seq_len)\n",
        "    if dropout is not None:\n",
        "      attention_score = nn.Dropout(attention_score)\n",
        "\n",
        "    return (attention_score @ value), attention_score\n",
        "\n",
        "  def forward(self, q, k, v, mask): #mask used to restrick some words to interect with other words\n",
        "    query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "    key  = self.w_k(k)\n",
        "    value = self.w_v(v)\n",
        "\n",
        "    # divid for multi head\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, head, d_k) --> (batch, head, seq_len, d_k)\n",
        "    query = query.view(query.shape[0], query.shape[1], self.head, self.d_k).transpose(1, 2)\n",
        "    key = key.view(key.shape[0], key.shape[1], self.head, self.d_k).transpose(1, 2)\n",
        "    value = value.view(value.shape[0], value.shape[1], self.head, self.d_k).transpose(1, 2)\n",
        "\n",
        "    x, self.attention_score  = MultiheadAttentionBlock.attention(query, key, value, self.mask, self.dropout)\n",
        "\n",
        "    # (batch, head, seq_len, d_k) --> (batch, seq_len, head, d_k) --> (batch, seq_len, d_model)\n",
        "    x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.head*self.d_k) # contiguous() used, because we want contiguous memory allocation\n",
        "\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "    return self.w_o(x)\n"
      ],
      "metadata": {
        "id": "5doPBFiQywuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual connection"
      ],
      "metadata": {
        "id": "TD8RDP9ZBQ7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self, dropout_p: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "    self.norm = LayerNorm()\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "id": "C_Kowq9iywrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Block"
      ],
      "metadata": {
        "id": "hJTqnBWTCJfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, self_attention_block: MultiheadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout_p: float):\n",
        "    super().__init__()\n",
        "    self.self_attention_block  = self_attention_block,\n",
        "    self.feed_forward_block = feed_forward_block\n",
        "    self.residualConnection = nn.ModuleList([ResidualConnection(dropout_p) for _ in range(2)])\n",
        "\n",
        "  def forward(self, x, src_mask):\n",
        "    x = self.residualConnection[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
        "    x = self.residualConnection[1](x, self.feed_forward_block)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "wNMEblNjywpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "sjE8TY5rKBRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, layers: nn.ModuleList):\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNorm()\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)\n"
      ],
      "metadata": {
        "id": "IGpqhTDsywnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Block"
      ],
      "metadata": {
        "id": "W8MbfSJhOXka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, self_attention_block: MultiheadAttentionBlock, cross_attention_block: MultiheadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout_p: float):\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.cross_attention_block = cross_attention_block\n",
        "    self.feed_forward_block = feed_forward_block\n",
        "    self.residualConnection = nn.ModuleList([ResidualConnection(dropout_p) for _ in range(3)])\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    # src_mask: it is for source language\n",
        "    # tgt_mask: it is for target language\n",
        "\n",
        "    x = self.residualConnection[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "    x = self.residualConnection[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask)) # query comming from the decoder and key and value comming from the encoder\n",
        "    x = self.residualConnection[2](x, self.feed_forward_block(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "mYOffJzCywjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder block"
      ],
      "metadata": {
        "id": "8r7LZQMBTR24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, layers: nn.ModuleList):\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNorm()\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ],
      "metadata": {
        "id": "ovNBariHywhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### last decoder output layer (projection layer)"
      ],
      "metadata": {
        "id": "d7akBO2tUdE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "    return torch.log_softmax(self.proj(x), dim = -1)\n"
      ],
      "metadata": {
        "id": "zeMXCNWJywfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer\n"
      ],
      "metadata": {
        "id": "WxkgwCWqVi-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, encoder: Encoder, decoder: Decoder, src_embedding: WordEmbedding, tgt_embedding: WordEmbedding, src_pos: PostionalEmbedding, tgt_pos: PostionalEmbedding, proj: ProjectionLayer):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embedding\n",
        "    self.tgt_embed = tgt_embedding\n",
        "    self.src_pos = src_pos\n",
        "    self.tgt_pos = tgt_pos\n",
        "    self.projectionLayer = proj\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    src = self.src_embed(src)\n",
        "    src = self.src_pos(src)\n",
        "    return self.encoder(src, src_mask)\n",
        "\n",
        "  def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "    tgt = self.tgt_embed(tgt)\n",
        "    tgt = self.tgt_pos(tgt)\n",
        "    return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "  def projection(self, x):\n",
        "    return self.projectionLayer(x)\n"
      ],
      "metadata": {
        "id": "gekhjNtpVmeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Tranformer"
      ],
      "metadata": {
        "id": "lCjfPCuOZCf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTransformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, head: int= 8, d_ff: int= 2048, N: int=6, dropout_p: float = 0.1):\n",
        "  # create source and target embedding\n",
        "  src_embedding = WordEmbedding(d_model, src_vocab_size)\n",
        "  tgt_embedding = WordEmbedding(d_model, tgt_vocab_size)\n",
        "\n",
        "  # create postional embedding for source and target\n",
        "  src_pos_embed = PostionalEmbedding(d_model, src_seq_len, dropout_p)\n",
        "  tgt_pos_embed = PostionalEmbedding(d_model, tgt_seq_len, dropout_p)\n",
        "\n",
        "  EncoderBlocks = []\n",
        "  for _ in range(N):\n",
        "    encoder_self_attention = MultiheadAttentionBlock(d_model, head, dropout_p)\n",
        "    feed_forward = FeedForwardBlock(d_model, d_ff, dropout_p)\n",
        "    encoder_block = EncoderBlock(encoder_self_attention, feed_forward, dropout_p)\n",
        "    EncoderBlocks.append(encoder_block)\n",
        "\n",
        "  DecoderBlocks = []\n",
        "  for _ in range(N):\n",
        "    decoder_self_attention = MultiheadAttentionBlock(d_model, head, dropout_p)\n",
        "    decoder_cross_attention = MultiheadAttentionBlock(d_model, head, dropout_p)\n",
        "    feed_forward = FeedForwardBlock(d_model, d_ff, dropout_p)\n",
        "    decoder_block = DecoderBlock(decoder_self_attention, decoder_cross_attention, feed_forward, dropout_p)\n",
        "    DecoderBlocks.append(decoder_block)\n",
        "\n",
        "  # create encoder and decoder\n",
        "  encoder = Encoder(nn.ModuleList(EncoderBlocks))\n",
        "  decoder = Decoder(nn.ModuleList(DecoderBlocks))\n",
        "\n",
        "  # projection layer\n",
        "  projectionLayer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "  # Transformer\n",
        "  transformer = Transformer(encoder, decoder, src_embedding, tgt_embedding, src_pos_embed, tgt_pos_embed, projectionLayer)\n",
        "\n",
        "  # initialize paramers so training faster\n",
        "  for p in transformer.parameter():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform(p)\n",
        "\n",
        "  return transformer"
      ],
      "metadata": {
        "id": "UnuMFCWHZFuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Language Translation from English to Italian using Transformer"
      ],
      "metadata": {
        "id": "wyZ9wTUXfXGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install datasets --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v41xe6Sg94a",
        "outputId": "7ce19833-fcd6-4b70-8dd1-d2a7c0b97696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "from pathlib import Path #create absolut path using relative path"
      ],
      "metadata": {
        "id": "QbQUVp3ree1q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "metadata": {
        "id": "8rBl0oOvSuni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "5LoFhmkRiOBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_sentence(dataset, lang):\n",
        "  for item in dataset:\n",
        "    yield item['translation'][lang]\n",
        "\n",
        "def buildTokenizer(config, dataset, lang):\n",
        "  # Ex: config['tokenizer_file'] = '../tokenizers/tokenizer_{}.json}'\n",
        "  tokenizer_path = Path(config['tokenizer_file'].formate(lang))\n",
        "  if not Path.exists(tokenizer_path):\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "    tokenizer.pre_tokenizers = Whitespace()\n",
        "    trainer = WordLevelTrainer(special_tokens = ['[UNK]', '[PAD]', '[SOS]', '[EOS]'], min_frequency=2)\n",
        "    tokenizer.train_from_iterator(get_all_sentence(dataset, lang), trainer=trainer)\n",
        "    tokenizer.save(str(tokenizer_path))\n",
        "  else:\n",
        "    tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "jcKbgPSteezY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get dataset from HuggingFace"
      ],
      "metadata": {
        "id": "EBuV9KZgl2eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(config):\n",
        "  ds_raw = load_dataset('opus_book', f\"{config['lang-src']-config['lang-tgt']}\", split='train')\n",
        "\n",
        "  # build tokenizers\n",
        "  tokenizer_src = buildTokenizer(config, ds_row, config['lang-src'])\n",
        "  tokenizer_tgt = buildTokenizer(config, ds_row, config['lang-tgt'])\n",
        "\n",
        "  #split dataset int train and validation set\n",
        "  train_size = int(0.9*len(ds_raw))\n",
        "  val_size = len(ds_raw) - train_size\n",
        "  train_raw, val_raw = random_split(ds_raw, [train_size, val_size])"
      ],
      "metadata": {
        "id": "MHD4v34Jeexj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(nn.Module):\n",
        "  def __init__(self, dataset, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "    super().__init__()\n",
        "    self.dataset = dataset\n",
        "    self.tokenizer_src = tokenizer_src\n",
        "    self.tokenizer_tgt = tokenizer_tgt\n",
        "    self.src_lang = src_lang\n",
        "    self.tgt_lang = tgt_lang\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "    self.sos_token = torch.tensor(self.tokenizer_src.token_to_id(['[SOS]']), dtype=torch.int64)\n",
        "    self.pad_token = torch.tensor(self.tokenizer_src.token_to_id(['[PAD]']), dtype=torch.int64)\n",
        "    self.eos_token = torch.tensor(self.tokenizer_src.token_to_id(['[EOS]']), dtype=torch.int64)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index: Any):\n",
        "    src_target_text = self.dataset[index]\n",
        "    src_text = src_target_text['translation'][self.src_lang]\n",
        "    tgt_text = src_target_text['translation'][self.tgt_lang]\n",
        "\n",
        "    enc_input_tokens = self.tokenizer_src.encode(src_text).ids #convert each src word into id give as array of id's\n",
        "    dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "    enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2 # 2 becasue we add [SOS] and [EOS]\n",
        "    dec_num_padding_tokens = self.seq_len = len(dec_input_tokens) -  1 # 1 because we only add [SOS] to the decoder side\n",
        "\n",
        "    if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "      raise ValueError('Sentence is too long')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uFNbBhIceewG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtwutIR9eeuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YrEYJ_jdeest"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UM4WfR4Deeq0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}