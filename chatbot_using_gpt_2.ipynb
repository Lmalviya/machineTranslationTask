{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoIu/DYKyTB2Gy4v1gDYXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lmalviya/machineTranslationTask/blob/main/chatbot_using_gpt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of this notebook\n",
        "1. Fine tuen GPT2 model for Mental Health Counseling Chat bot"
      ],
      "metadata": {
        "id": "6gV3Sol9me3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KdJCecY0MLe",
        "outputId": "b86c9bdb-2493-4832-a04f-2d105d3a3a07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CNaKwVNvww76"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config():\n",
        "  return {\n",
        "      'datasetName': \"Amod/mental_health_counseling_conversations\",\n",
        "      'split': 'train',\n",
        "      'max_len': 1024,\n",
        "      'batch_size': 2,\n",
        "      'shuffle':True,\n",
        "      'lr': 1e-04,\n",
        "      'num_epochs': 2,\n",
        "  }"
      ],
      "metadata": {
        "id": "TRo0QwEEzxCl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocess(Dataset):\n",
        "  def __init__(self, data, tokenizer, max_len:int = 1024):\n",
        "    super().__init__()\n",
        "\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    items = self.data[idx]\n",
        "    context = items['Context']\n",
        "    response =  items['Response']\n",
        "\n",
        "    input_text = f\"{context}\\n [ANSWER]: {response}\"\n",
        "\n",
        "    input_tokens = self.tokenizer(input_text, return_tensors='pt')\n",
        "\n",
        "    pad_size = self.max_len - input_tokens['input_ids'].size(1)\n",
        "\n",
        "\n",
        "    input_ids = torch.cat((\n",
        "        input_tokens['input_ids'],\n",
        "        torch.tensor([self.tokenizer.encode('[PAD]')]*pad_size, dtype=torch.int64).view(1, pad_size)\n",
        "    ), -1)\n",
        "\n",
        "\n",
        "    input_mask = torch.cat((\n",
        "        input_tokens['attention_mask'],\n",
        "        torch.tensor([0]*pad_size, dtype=torch.int64).view(1, pad_size)\n",
        "    ), -1)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'context': context,\n",
        "        'responce': response\n",
        "    }"
      ],
      "metadata": {
        "id": "PMsq1ruAw6vl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(config, tokenizer):\n",
        "  raw_data = load_dataset(config['datasetName'], split=config['split'])\n",
        "  num_of_data_points = len(raw_data)\n",
        "\n",
        "  train_size = int(0.8*num_of_data_points)\n",
        "  val_size = num_of_data_points - train_size\n",
        "  train_raw, val_raw = random_split(raw_data, [train_size, val_size])\n",
        "\n",
        "  train_class = DataPreprocess(train_raw, tokenizer, config['max_len'])\n",
        "  val_class = DataPreprocess(val_raw, tokenizer, config['max_len'])\n",
        "\n",
        "  train_ds = DataLoader(train_class, batch_size=config['batch_size'], shuffle=config['shuffle'])\n",
        "  val_ds = DataLoader(val_class, batch_size=config['batch_size'], shuffle=config['shuffle'])\n",
        "\n",
        "  return train_ds, val_ds\n",
        "\n"
      ],
      "metadata": {
        "id": "kPpbJ7Nn1JNp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_and_tokenizer():\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "  tokenizer.add_special_tokens({\n",
        "      'pad_token': '[PAD]',\n",
        "      'bos_token': '[SOS]',\n",
        "      'eos_token': '[EOS]'\n",
        "  })\n",
        "  tokenizer.add_tokens('[ANSWER]:')\n",
        "\n",
        "  model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "  return model, tokenizer"
      ],
      "metadata": {
        "id": "sNWMVdXLw6tt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, device):\n",
        "  model.eval()\n",
        "\n",
        "  batch_iterator = tqdm(data)\n",
        "\n",
        "  cumulative_loss = 0.0\n",
        "  for batch in batch_iterator:\n",
        "    input_ids = data['input_ids'].to(device)\n",
        "    input_mask = data['input_mask'].to(device)\n",
        "    loss = model(input_ids, attention_mask=input_mask, labels=input_ids).loss\n",
        "    batch_iterator.set_postfix({'val loss': f\"{loss.item():6.3f}\"})\n",
        "    cumulative_loss += loss.item()\n",
        "\n",
        "  return cumulative_loss/len(data)\n",
        ""
      ],
      "metadata": {
        "id": "R_LHmj7vMu4R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(config):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  print(f\"Current device is used: {device}\")\n",
        "\n",
        "  model, tokenizer = get_model_and_tokenizer()\n",
        "  model.to(device)\n",
        "\n",
        "  train_ds, val_ds = get_data(config, tokenizer)\n",
        "\n",
        "  # Tensorboard\n",
        "  writer = SummaryWriter('Mental Health Counseling Chat Boat')\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "  global_step = 0\n",
        "\n",
        "  for epoch in range(config['num_epochs']):\n",
        "    torch.cuda.empty_cache()\n",
        "    model.train()\n",
        "\n",
        "    batch_iterator = tqdm(train_ds, desc=f\"Processing Epoch: {epoch:02d}\")\n",
        "    for batch in batch_iterator:\n",
        "      optimizer.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device) # (batch, seq_len)\n",
        "      input_mask = batch['input_mask'].to(device) #(batch, seq_len)\n",
        "\n",
        "      loss = model(input_ids, attention_mask=input_mask, labels=input_ids).loss\n",
        "      batch_iterator.set_postfix({ \"train loss\": f\"{loss.item():6.3f}\" })\n",
        "\n",
        "      writer.add_scalar(\"train loss\", loss.item(), epoch)\n",
        "      writer.flush()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    val_loss = evaluate(model, val_ds, device)\n",
        "    writer.add_scalar(\"val loss\", loss.item(), epoch)\n",
        "    writer.flush()\n",
        "\n",
        "    return writer\n"
      ],
      "metadata": {
        "id": "o6GPavDgw6qU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_config()\n",
        "wt = train_model(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2yNwuk4aw6og",
        "outputId": "34858a20-8bc3-4e47-89d2-1e1b6c65e62c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device is used: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Processing Epoch: 00:   0%|          | 0/1405 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "551\n",
            "631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 1/1405 [00:01<43:48,  1.87s/it, train loss=58.012]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "934\n",
            "634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 2/1405 [00:02<22:18,  1.05it/s, train loss=22.543]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "828\n",
            "827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 3/1405 [00:02<19:41,  1.19it/s, train loss=13.799]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "858\n",
            "825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 4/1405 [00:03<17:53,  1.31it/s, train loss=9.209]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "757\n",
            "692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 5/1405 [00:04<17:13,  1.35it/s, train loss=12.652]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696\n",
            "772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 6/1405 [00:04<16:45,  1.39it/s, train loss=9.053]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "887\n",
            "767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   0%|          | 7/1405 [00:05<16:20,  1.43it/s, train loss=3.655]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "831\n",
            "591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 8/1405 [00:06<16:09,  1.44it/s, train loss=9.370]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "807\n",
            "95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 9/1405 [00:06<16:02,  1.45it/s, train loss=9.167]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "552\n",
            "744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 10/1405 [00:07<15:53,  1.46it/s, train loss=3.597]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "916\n",
            "829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 11/1405 [00:08<15:50,  1.47it/s, train loss=2.279]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "793\n",
            "711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 12/1405 [00:08<15:48,  1.47it/s, train loss=2.426]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "453\n",
            "940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 13/1405 [00:09<16:00,  1.45it/s, train loss=2.573]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "731\n",
            "669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 14/1405 [00:10<15:59,  1.45it/s, train loss=2.558]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "913\n",
            "927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 15/1405 [00:11<16:19,  1.42it/s, train loss=1.323]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "876\n",
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 16/1405 [00:11<15:48,  1.46it/s, train loss=3.431]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "659\n",
            "903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|          | 17/1405 [00:12<15:38,  1.48it/s, train loss=1.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "848\n",
            "790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|▏         | 18/1405 [00:13<15:39,  1.48it/s, train loss=1.641]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610\n",
            "922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|▏         | 19/1405 [00:13<15:40,  1.47it/s, train loss=1.853]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "903\n",
            "813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|▏         | 20/1405 [00:14<15:49,  1.46it/s, train loss=1.286]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "837\n",
            "796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   1%|▏         | 21/1405 [00:15<15:43,  1.47it/s, train loss=1.448]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "749\n",
            "448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 22/1405 [00:15<15:37,  1.47it/s, train loss=2.703]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438\n",
            "803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 23/1405 [00:16<15:39,  1.47it/s, train loss=2.501]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "868\n",
            "819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 24/1405 [00:17<15:39,  1.47it/s, train loss=1.154]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "746\n",
            "765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 25/1405 [00:17<15:55,  1.44it/s, train loss=1.724]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630\n",
            "854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 26/1405 [00:18<15:33,  1.48it/s, train loss=1.820]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766\n",
            "785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 27/1405 [00:19<15:43,  1.46it/s, train loss=1.568]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "710\n",
            "898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 28/1405 [00:19<15:35,  1.47it/s, train loss=1.402]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "910\n",
            "576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 29/1405 [00:20<15:39,  1.46it/s, train loss=1.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "908\n",
            "807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 30/1405 [00:21<15:40,  1.46it/s, train loss=1.056]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "424\n",
            "952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 31/1405 [00:21<15:42,  1.46it/s, train loss=1.996]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "947\n",
            "856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 32/1405 [00:22<15:51,  1.44it/s, train loss=1.165]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "671\n",
            "876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 33/1405 [00:23<15:55,  1.44it/s, train loss=1.557]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "832\n",
            "894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 34/1405 [00:24<15:57,  1.43it/s, train loss=0.932]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "789\n",
            "851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   2%|▏         | 35/1405 [00:24<15:38,  1.46it/s, train loss=1.293]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "839\n",
            "648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 36/1405 [00:25<15:39,  1.46it/s, train loss=1.556]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "619\n",
            "840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 37/1405 [00:26<15:38,  1.46it/s, train loss=1.762]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "754\n",
            "240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 38/1405 [00:26<15:39,  1.45it/s, train loss=3.205]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "893\n",
            "911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 39/1405 [00:27<15:38,  1.46it/s, train loss=0.777]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 40/1405 [00:28<15:38,  1.45it/s, train loss=1.676]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "544\n",
            "659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 41/1405 [00:28<15:38,  1.45it/s, train loss=2.313]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "729\n",
            "590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 42/1405 [00:29<15:40,  1.45it/s, train loss=2.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "263\n",
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 43/1405 [00:30<15:41,  1.45it/s, train loss=4.809]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "515\n",
            "647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 44/1405 [00:30<15:43,  1.44it/s, train loss=2.180]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "585\n",
            "810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 45/1405 [00:31<15:44,  1.44it/s, train loss=1.489]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771\n",
            "806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch: 00:   3%|▎         | 46/1405 [00:32<15:42,  1.44it/s, train loss=1.110]Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Processing Epoch: 00:   3%|▎         | 46/1405 [00:32<15:56,  1.42it/s, train loss=1.110]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "987\n",
            "-147\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "invalid shape dimension -147",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1f176a9bdeaa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-1d6e9a2ba9d5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbatch_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Processing Epoch: {epoch:02d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8540f1d9333c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     input_ids = torch.cat((\n\u001b[1;32m     27\u001b[0m         \u001b[0minput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[PAD]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     ), -1)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid shape dimension -147"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save({\n",
        "#         'epoch': epoch,\n",
        "#         'model_state_dict': model.state_dict(),\n",
        "#         'optimizer_state_dict': optimizer.state_dict(),\n",
        "#         'global_step': global_step\n",
        "#     }, model_file_path)"
      ],
      "metadata": {
        "id": "NvfX8PJmw6iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nW59-nr9w6gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfTyHdnIw6ea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}